{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "oPxcCsvzwJrC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Flatten, Dense, Dropout\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import cv2\n",
        "\n",
        "from tensorflow.keras import utils as np_utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GS9hMlQh_PYh"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_data=pd.read_csv(\"/content/cdsaml/fer2013.csv\")\n",
        "print(emotion_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZtD1HVbw5tI",
        "outputId": "da48d8f3-91e6-4c25-9214-e90958a4b070"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     emotion                                             pixels     Usage\n",
            "0          0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
            "1          0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
            "2          2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
            "3          4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
            "4          6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n",
            "..       ...                                                ...       ...\n",
            "120        0  254 253 253 245 215 175 179 137 62 29 25 50 11...  Training\n",
            "121        2  233 234 218 197 208 194 200 223 233 232 225 20...  Training\n",
            "122        0  42 44 44 44 48 49 49 52 60 31 18 25 38 37 17 2...  Training\n",
            "123        0  107 85 75 120 161 164 160 152 147 149 158 164 ...  Training\n",
            "124        3  105 104 107 88 43 14 30 50 38 11 5 16 25 43 71...       NaN\n",
            "\n",
            "[125 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "for index,row in emotion_data.iterrows():\n",
        "    k = row['pixels'].split(\" \")\n",
        "    if row['Usage'] == 'Training':\n",
        "        X_train.append(np.array(k))\n",
        "        y_train.append(row['emotion'])\n",
        "    elif row['Usage'] == 'PublicTest':\n",
        "        X_test.append(np.array(k))\n",
        "        y_test.append(row['emotion'])"
      ],
      "metadata": {
        "id": "qwynRedI1Ad0"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)\n",
        "\n",
        "y_train= np_utils.to_categorical(y_train, num_classes=7)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes=7)"
      ],
      "metadata": {
        "id": "ZtsE2Ob313VJ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2ZxZZoUVorIQ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqhus4NBleXA",
        "outputId": "be05b5b4-4eb4-44e4-dbb5-4c9ed9cc430c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[['70'],\n",
              "         ['80'],\n",
              "         ['82'],\n",
              "         ...,\n",
              "         ['52'],\n",
              "         ['43'],\n",
              "         ['41']],\n",
              "\n",
              "        [['65'],\n",
              "         ['61'],\n",
              "         ['58'],\n",
              "         ...,\n",
              "         ['56'],\n",
              "         ['52'],\n",
              "         ['44']],\n",
              "\n",
              "        [['50'],\n",
              "         ['43'],\n",
              "         ['54'],\n",
              "         ...,\n",
              "         ['49'],\n",
              "         ['56'],\n",
              "         ['47']],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [['91'],\n",
              "         ['65'],\n",
              "         ['42'],\n",
              "         ...,\n",
              "         ['72'],\n",
              "         ['56'],\n",
              "         ['43']],\n",
              "\n",
              "        [['77'],\n",
              "         ['82'],\n",
              "         ['79'],\n",
              "         ...,\n",
              "         ['105'],\n",
              "         ['70'],\n",
              "         ['46']],\n",
              "\n",
              "        [['77'],\n",
              "         ['72'],\n",
              "         ['84'],\n",
              "         ...,\n",
              "         ['106'],\n",
              "         ['109'],\n",
              "         ['82']]],\n",
              "\n",
              "\n",
              "       [[['151'],\n",
              "         ['150'],\n",
              "         ['147'],\n",
              "         ...,\n",
              "         ['129'],\n",
              "         ['140'],\n",
              "         ['120']],\n",
              "\n",
              "        [['151'],\n",
              "         ['149'],\n",
              "         ['149'],\n",
              "         ...,\n",
              "         ['122'],\n",
              "         ['141'],\n",
              "         ['137']],\n",
              "\n",
              "        [['151'],\n",
              "         ['151'],\n",
              "         ['156'],\n",
              "         ...,\n",
              "         ['109'],\n",
              "         ['123'],\n",
              "         ['146']],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [['188'],\n",
              "         ['188'],\n",
              "         ['121'],\n",
              "         ...,\n",
              "         ['185'],\n",
              "         ['185'],\n",
              "         ['186']],\n",
              "\n",
              "        [['188'],\n",
              "         ['187'],\n",
              "         ['196'],\n",
              "         ...,\n",
              "         ['186'],\n",
              "         ['182'],\n",
              "         ['187']],\n",
              "\n",
              "        [['186'],\n",
              "         ['184'],\n",
              "         ['185'],\n",
              "         ...,\n",
              "         ['193'],\n",
              "         ['183'],\n",
              "         ['184']]],\n",
              "\n",
              "\n",
              "       [[['231'],\n",
              "         ['212'],\n",
              "         ['156'],\n",
              "         ...,\n",
              "         ['44'],\n",
              "         ['27'],\n",
              "         ['16']],\n",
              "\n",
              "        [['229'],\n",
              "         ['175'],\n",
              "         ['148'],\n",
              "         ...,\n",
              "         ['27'],\n",
              "         ['35'],\n",
              "         ['27']],\n",
              "\n",
              "        [['214'],\n",
              "         ['156'],\n",
              "         ['157'],\n",
              "         ...,\n",
              "         ['28'],\n",
              "         ['22'],\n",
              "         ['28']],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [['241'],\n",
              "         ['245'],\n",
              "         ['250'],\n",
              "         ...,\n",
              "         ['57'],\n",
              "         ['101'],\n",
              "         ['146']],\n",
              "\n",
              "        [['246'],\n",
              "         ['250'],\n",
              "         ['252'],\n",
              "         ...,\n",
              "         ['78'],\n",
              "         ['105'],\n",
              "         ['162']],\n",
              "\n",
              "        [['250'],\n",
              "         ['251'],\n",
              "         ['250'],\n",
              "         ...,\n",
              "         ['88'],\n",
              "         ['110'],\n",
              "         ['152']]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[['233'],\n",
              "         ['234'],\n",
              "         ['218'],\n",
              "         ...,\n",
              "         ['213'],\n",
              "         ['211'],\n",
              "         ['213']],\n",
              "\n",
              "        [['233'],\n",
              "         ['235'],\n",
              "         ['216'],\n",
              "         ...,\n",
              "         ['225'],\n",
              "         ['222'],\n",
              "         ['219']],\n",
              "\n",
              "        [['232'],\n",
              "         ['233'],\n",
              "         ['209'],\n",
              "         ...,\n",
              "         ['224'],\n",
              "         ['225'],\n",
              "         ['223']],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [['175'],\n",
              "         ['187'],\n",
              "         ['207'],\n",
              "         ...,\n",
              "         ['80'],\n",
              "         ['103'],\n",
              "         ['131']],\n",
              "\n",
              "        [['179'],\n",
              "         ['192'],\n",
              "         ['211'],\n",
              "         ...,\n",
              "         ['30'],\n",
              "         ['78'],\n",
              "         ['111']],\n",
              "\n",
              "        [['184'],\n",
              "         ['197'],\n",
              "         ['216'],\n",
              "         ...,\n",
              "         ['0'],\n",
              "         ['34'],\n",
              "         ['82']]],\n",
              "\n",
              "\n",
              "       [[['42'],\n",
              "         ['44'],\n",
              "         ['44'],\n",
              "         ...,\n",
              "         ['147'],\n",
              "         ['159'],\n",
              "         ['169']],\n",
              "\n",
              "        [['38'],\n",
              "         ['42'],\n",
              "         ['46'],\n",
              "         ...,\n",
              "         ['147'],\n",
              "         ['157'],\n",
              "         ['163']],\n",
              "\n",
              "        [['47'],\n",
              "         ['64'],\n",
              "         ['76'],\n",
              "         ...,\n",
              "         ['147'],\n",
              "         ['156'],\n",
              "         ['156']],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [['154'],\n",
              "         ['139'],\n",
              "         ['176'],\n",
              "         ...,\n",
              "         ['96'],\n",
              "         ['104'],\n",
              "         ['123']],\n",
              "\n",
              "        [['89'],\n",
              "         ['206'],\n",
              "         ['239'],\n",
              "         ...,\n",
              "         ['83'],\n",
              "         ['103'],\n",
              "         ['150']],\n",
              "\n",
              "        [['64'],\n",
              "         ['149'],\n",
              "         ['252'],\n",
              "         ...,\n",
              "         ['68'],\n",
              "         ['106'],\n",
              "         ['168']]],\n",
              "\n",
              "\n",
              "       [[['107'],\n",
              "         ['85'],\n",
              "         ['75'],\n",
              "         ...,\n",
              "         ['68'],\n",
              "         ['42'],\n",
              "         ['32']],\n",
              "\n",
              "        [['100'],\n",
              "         ['74'],\n",
              "         ['87'],\n",
              "         ...,\n",
              "         ['91'],\n",
              "         ['69'],\n",
              "         ['34']],\n",
              "\n",
              "        [['96'],\n",
              "         ['78'],\n",
              "         ['114'],\n",
              "         ...,\n",
              "         ['108'],\n",
              "         ['93'],\n",
              "         ['61']],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [['63'],\n",
              "         ['122'],\n",
              "         ['130'],\n",
              "         ...,\n",
              "         ['70'],\n",
              "         ['65'],\n",
              "         ['59']],\n",
              "\n",
              "        [['16'],\n",
              "         ['45'],\n",
              "         ['91'],\n",
              "         ...,\n",
              "         ['65'],\n",
              "         ['57'],\n",
              "         ['51']],\n",
              "\n",
              "        [['23'],\n",
              "         ['15'],\n",
              "         ['19'],\n",
              "         ...,\n",
              "         ['56'],\n",
              "         ['51'],\n",
              "         ['46']]]], dtype='<U3')"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array(X_train, dtype = 'uint8')\n",
        "y_train = np.array(y_train, dtype = 'uint8')\n",
        "X_test = np.array(X_test, dtype = 'uint8')\n",
        "y_test = np.array(y_test, dtype = 'uint8')\n"
      ],
      "metadata": {
        "id": "gBhAmxK5cqeb"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator \n",
        "datagen = ImageDataGenerator( \n",
        "    rescale=1./255,\n",
        "    rotation_range = 10,\n",
        "    horizontal_flip = True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    fill_mode = 'nearest')"
      ],
      "metadata": {
        "id": "uAOKmYBIDNo-"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testgen = ImageDataGenerator(rescale=1./255)\n",
        "datagen.fit(X_train)"
      ],
      "metadata": {
        "id": "Um7BvMsHc8_l"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64"
      ],
      "metadata": {
        "id": "3bZ6re9Dc9Ca"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_flow = datagen.flow(X_train, y_train, batch_size=batch_size) \n",
        "test_flow = testgen.flow(X_test, y_test, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "HZUlQiQ6dFyr"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "from keras.regularizers import l1, l2\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "Wqi1GbJAdJAl"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FER_Model(input_shape=(48,48,1)):\n",
        "    # first input model\n",
        "    visible = Input(shape=input_shape, name='input')\n",
        "    num_classes = 7\n",
        "    #the 1-st block\n",
        "    conv1_1 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_1')(visible)\n",
        "    conv1_1 = BatchNormalization()(conv1_1)\n",
        "    conv1_2 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_2')(conv1_1)\n",
        "    conv1_2 = BatchNormalization()(conv1_2)\n",
        "    pool1_1 = MaxPooling2D(pool_size=(2,2), name = 'pool1_1')(conv1_2)\n",
        "    drop1_1 = Dropout(0.3, name = 'drop1_1')(pool1_1)#the 2-nd block\n",
        "    conv2_1 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_1')(drop1_1)\n",
        "    conv2_1 = BatchNormalization()(conv2_1)\n",
        "    conv2_2 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_2')(conv2_1)\n",
        "    conv2_2 = BatchNormalization()(conv2_2)\n",
        "    conv2_3 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_3')(conv2_2)\n",
        "    conv2_2 = BatchNormalization()(conv2_3)\n",
        "    pool2_1 = MaxPooling2D(pool_size=(2,2), name = 'pool2_1')(conv2_3)\n",
        "    drop2_1 = Dropout(0.3, name = 'drop2_1')(pool2_1)#the 3-rd block\n",
        "    conv3_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_1')(drop2_1)\n",
        "    conv3_1 = BatchNormalization()(conv3_1)\n",
        "    conv3_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_2')(conv3_1)\n",
        "    conv3_2 = BatchNormalization()(conv3_2)\n",
        "    conv3_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_3')(conv3_2)\n",
        "    conv3_3 = BatchNormalization()(conv3_3)\n",
        "    conv3_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_4')(conv3_3)\n",
        "    conv3_4 = BatchNormalization()(conv3_4)\n",
        "    pool3_1 = MaxPooling2D(pool_size=(2,2), name = 'pool3_1')(conv3_4)\n",
        "    drop3_1 = Dropout(0.3, name = 'drop3_1')(pool3_1)#the 4-th block\n",
        "    conv4_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_1')(drop3_1)\n",
        "    conv4_1 = BatchNormalization()(conv4_1)\n",
        "    conv4_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_2')(conv4_1)\n",
        "    conv4_2 = BatchNormalization()(conv4_2)\n",
        "    conv4_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_3')(conv4_2)\n",
        "    conv4_3 = BatchNormalization()(conv4_3)\n",
        "    conv4_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_4')(conv4_3)\n",
        "    conv4_4 = BatchNormalization()(conv4_4)\n",
        "    pool4_1 = MaxPooling2D(pool_size=(2,2), name = 'pool4_1')(conv4_4)\n",
        "    drop4_1 = Dropout(0.3, name = 'drop4_1')(pool4_1)\n",
        "    \n",
        "    #the 5-th block\n",
        "    conv5_1 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_1')(drop4_1)\n",
        "    conv5_1 = BatchNormalization()(conv5_1)\n",
        "    conv5_2 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_2')(conv5_1)\n",
        "    conv5_2 = BatchNormalization()(conv5_2)\n",
        "    conv5_3 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_3')(conv5_2)\n",
        "    conv5_3 = BatchNormalization()(conv5_3)\n",
        "    conv5_4 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_4')(conv5_3)\n",
        "    conv5_3 = BatchNormalization()(conv5_3)\n",
        "    pool5_1 = MaxPooling2D(pool_size=(2,2), name = 'pool5_1')(conv5_4)\n",
        "    drop5_1 = Dropout(0.3, name = 'drop5_1')(pool5_1)#Flatten and output\n",
        "    flatten = Flatten(name = 'flatten')(drop5_1)\n",
        "    ouput = Dense(num_classes, activation='softmax', name = 'output')(flatten)# create model \n",
        "    model = Model(inputs =visible, outputs = ouput)\n",
        "    # summary layers\n",
        "    print(model.summary())\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "EpOAQqA2_Qe7"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FER_Model()\n",
        "opt = Adam(lr=0.0001, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "RvnvuFQsDvdL",
        "outputId": "4f1bbd18-2ef1-4a58-ae34-02209f29ae00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 48, 48, 1)]       0         \n",
            "                                                                 \n",
            " conv1_1 (Conv2D)            (None, 48, 48, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization_17 (Bat  (None, 48, 48, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv1_2 (Conv2D)            (None, 48, 48, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_18 (Bat  (None, 48, 48, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " pool1_1 (MaxPooling2D)      (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " drop1_1 (Dropout)           (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " conv2_1 (Conv2D)            (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_19 (Bat  (None, 24, 24, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2_2 (Conv2D)            (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_20 (Bat  (None, 24, 24, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2_3 (Conv2D)            (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " pool2_1 (MaxPooling2D)      (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " drop2_1 (Dropout)           (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " conv3_1 (Conv2D)            (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_22 (Bat  (None, 12, 12, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3_2 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_23 (Bat  (None, 12, 12, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3_3 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_24 (Bat  (None, 12, 12, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3_4 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_25 (Bat  (None, 12, 12, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " pool3_1 (MaxPooling2D)      (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " drop3_1 (Dropout)           (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv4_1 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_26 (Bat  (None, 6, 6, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv4_2 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_27 (Bat  (None, 6, 6, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv4_3 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_28 (Bat  (None, 6, 6, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv4_4 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_29 (Bat  (None, 6, 6, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " pool4_1 (MaxPooling2D)      (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " drop4_1 (Dropout)           (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " conv5_1 (Conv2D)            (None, 3, 3, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 3, 3, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv5_2 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 3, 3, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv5_3 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_32 (Bat  (None, 3, 3, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv5_4 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " pool5_1 (MaxPooling2D)      (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " drop5_1 (Dropout)           (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,111,367\n",
            "Trainable params: 13,103,431\n",
            "Non-trainable params: 7,936\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100  \n",
        "history = model.fit_generator(train_flow, \n",
        "                    steps_per_epoch=len(X_train) / batch_size, \n",
        "                    epochs=num_epochs,  \n",
        "                    verbose=1,  \n",
        "                    validation_data=test_flow,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhSeqb-seDxW",
        "outputId": "d0029e97-670c-493c-f6e3-62f2d53c6cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 18s 9s/step - loss: 2.6218 - accuracy: 0.1855\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 16s 8s/step - loss: 2.1550 - accuracy: 0.2177\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.4944 - accuracy: 0.1855\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.3650 - accuracy: 0.2016\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 16s 8s/step - loss: 2.2036 - accuracy: 0.1694\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.0527 - accuracy: 0.2419\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.2968 - accuracy: 0.1935\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.3899 - accuracy: 0.1935\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 16s 8s/step - loss: 2.3618 - accuracy: 0.1613\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 16s 8s/step - loss: 2.2862 - accuracy: 0.1452\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.2298 - accuracy: 0.1532\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.0994 - accuracy: 0.2419\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.3908 - accuracy: 0.1613\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 16s 8s/step - loss: 2.1644 - accuracy: 0.1935\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 16s 8s/step - loss: 2.3232 - accuracy: 0.1452\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.2470 - accuracy: 0.1613\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.1985 - accuracy: 0.2339\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.0242 - accuracy: 0.2177\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 16s 8s/step - loss: 2.1752 - accuracy: 0.2097\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 16s 8s/step - loss: 2.1215 - accuracy: 0.2016\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.0781 - accuracy: 0.2742\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.0831 - accuracy: 0.2742\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 16s 8s/step - loss: 2.2122 - accuracy: 0.2097\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.2381 - accuracy: 0.2339\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 16s 8s/step - loss: 1.8990 - accuracy: 0.2419\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.0350 - accuracy: 0.2339\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 16s 8s/step - loss: 1.9655 - accuracy: 0.2903\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.1753 - accuracy: 0.1935\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.0168 - accuracy: 0.2823\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.2344 - accuracy: 0.1774\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.1346 - accuracy: 0.2258\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.0103 - accuracy: 0.2581\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 16s 8s/step - loss: 2.0357 - accuracy: 0.2500\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 1.9776 - accuracy: 0.2742\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.0507 - accuracy: 0.2419\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 16s 8s/step - loss: 2.0185 - accuracy: 0.2581\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 16s 8s/step - loss: 2.0414 - accuracy: 0.2339\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 16s 8s/step - loss: 2.1721 - accuracy: 0.1694\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 16s 9s/step - loss: 2.0552 - accuracy: 0.2500\n",
            "Epoch 40/100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "id": "hkgFvSrIlT1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "model = model_from_json(open(\"/content/model.json\", \"r\").read())\n",
        "model = model.load_weights('/content/model.h5')"
      ],
      "metadata": {
        "id": "T3v1wF88mO0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
      ],
      "metadata": {
        "id": "Mdzo_bQCotnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap=cv2.VideoCapture(0)\n",
        "\n",
        "while cap.isOpened():\n",
        "    res,frame=cap.read()\n",
        "    height, width , channel = frame.shape\n",
        "    gray_image= cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_haar_cascade.detectMultiScale(gray_image)\n",
        "    try:\n",
        "        for (x,y, w, h) in faces:\n",
        "            cv2.rectangle(frame, pt1 = (x,y),pt2 = (x+w, y+h), color = (255,0,0),thickness =  2)\n",
        "            roi_gray = gray_image[y-5:y+h+5,x-5:x+w+5]\n",
        "            roi_gray=cv2.resize(roi_gray,(48,48))\n",
        "            image_pixels = tf.keras.preprocessing.image.img_to_array(roi_gray)\n",
        "            image_pixels = np.expand_dims(image_pixels, axis = 0)\n",
        "            image_pixels /= 255\n",
        "            predictions = model.predict(image_pixels)\n",
        "            max_index = np.argmax(predictions[0])\n",
        "            emotion_detection = ['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
        "            emotion_prediction = emotion_detection[max_index]\n",
        "    except:\n",
        "      print(\"Some error occured\")\n"
      ],
      "metadata": {
        "id": "cO-PETr6pgKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap=cv2.VideoCapture(1)\n",
        "while cap.isOpened():\n",
        "    res,frame=cap.read()\n",
        "    height, width , channel = frame.shape\n",
        "\n",
        "    # Creating an Overlay window to write prediction and cofidencesub_img = frame[0:int(height/6),0:int(width)]black_rect = np.ones(sub_img.shape, dtype=np.uint8)*0\n",
        "    res = cv2.addWeighted(sub_img, 0.77, black_rect,0.23, 0)\n",
        "    FONT = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    FONT_SCALE = 0.8\n",
        "    FONT_THICKNESS = 2\n",
        "    lable_color = (10, 10, 255)\n",
        "    lable = \"Emotion Detection\"\n",
        "    lable_dimension = cv2.getTextSize(lable,FONT ,FONT_SCALE,FONT_THICKNESS)[0]\n",
        "    textX = int((res.shape[1] - lable_dimension[0]) / 2)\n",
        "    textY = int((res.shape[0] + lable_dimension[1]) / 2)\n",
        "    cv2.putText(res, lable, (textX,textY), FONT, FONT_SCALE, (0,0,0), FONT_THICKNESS)# prediction part --------------------------------------------------------------------------gray_image= cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_haar_cascade.detectMultiScale(gray_image )\n",
        "    try:\n",
        "        for (x,y, w, h) in faces:\n",
        "            cv2.rectangle(frame, pt1 = (x,y),pt2 = (x+w, y+h), color = (255,0,0),thickness =  2)\n",
        "            roi_gray = gray_image[y-5:y+h+5,x-5:x+w+5]\n",
        "            roi_gray=cv2.resize(roi_gray,(48,48))\n",
        "            image_pixels = img_to_array(roi_gray)\n",
        "            image_pixels = np.expand_dims(image_pixels, axis = 0)\n",
        "            image_pixels /= 255\n",
        "            predictions = model.predict(image_pixels)\n",
        "            max_index = np.argmax(predictions[0])\n",
        "            emotion_detection = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
        "            emotion_prediction = emotion_detection[max_index]\n",
        "            cv2.putText(res, \"Sentiment: {}\".format(emotion_prediction), (0,textY+22+5), FONT,0.7, lable_color,2)\n",
        "            lable_violation = 'Confidence: {}'.format(str(np.round(np.max(predictions[0])*100,1))+ \"%\")\n",
        "            violation_text_dimension = cv2.getTextSize(lable_violation,FONT,FONT_SCALE,FONT_THICKNESS )[0]\n",
        "            violation_x_axis = int(res.shape[1]- violation_text_dimension[0])\n",
        "            cv2.putText(res, lable_violation, (violation_x_axis,textY+22+5), FONT,0.7, lable_color,2)\n",
        "    except :\n",
        "        pass\n",
        "    frame[0:int(height/6),0:int(width)] = res\n",
        "    cv2.imshow('frame', frame)\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        breakcap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "S-eI2AQ72K68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zhYiGlOGDZ6V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}