{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a486f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7c1c75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/gb/CDSAML/Images/7.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a37ae02",
   "metadata": {},
   "source": [
    "# Image Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54417e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Images module from pillow\n",
    "from PIL import Image\n",
    "# Open the image by specifying the image path.\n",
    "image_file = Image.open(path)\n",
    "# the default\n",
    "image_file.save(\"/home/gb/CDSAML/Images/edited.jpg\", quality=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d377ff39",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a21b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = \"/home/gb/CDSAML/Images/edited.jpg\"\n",
    "face_classifier = cv.CascadeClassifier('/home/gb/CDSAML/opencv/data/haarcascades/haarcascade_frontalface_alt2.xml')\n",
    "resized = cv.imread(path2)\n",
    "gray = cv.cvtColor(resized, cv.COLOR_BGR2GRAY)\n",
    "''' Our classifier returns the ROI of the detected face as a tuple, \n",
    "It stores the top left coordinate and the bottom right coordiantes'''\n",
    "faces = face_classifier.detectMultiScale(gray, 1.0485258, 6)\n",
    "'''When no faces detected, face_classifier returns and empty tuple'''\n",
    "count_face = len(faces)\n",
    "\n",
    "#if len(faces)==0:\n",
    "    #print(\"No faces found\")\n",
    "'''We iterate through our faces array and draw a rectangle over each face in faces'''\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv.rectangle(resized, (x,y), (x+w,y+h), (127,0,255), 2)\n",
    "    cv.imshow('Face Detection', resized)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e40ad0",
   "metadata": {},
   "source": [
    "# People and Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c533eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = cv.imread(path2)\n",
    "cv.imshow('window',  img)\n",
    "cv.waitKey(1)\n",
    "\n",
    "# Load names of classes and get random colors\n",
    "classes = open('/home/gb/CDSAML/darknet/data/coco.names').read().strip().split('\\n')\n",
    "np.random.seed(42)\n",
    "colors = np.random.randint(0, 255, size=(len(classes), 3), dtype='uint8')\n",
    "\n",
    "# Give the configuration and weight files for the model and load the network.\n",
    "net = cv.dnn.readNetFromDarknet('/home/gb/CDSAML/darknet/cfg/yolov3.cfg', '/home/gb/CDSAML/darknet/yolov3.weights')\n",
    "net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "# net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "# determine the output layer\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# construct a blob from the image\n",
    "blob = cv.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "r = blob[0, 0, :, :]\n",
    "\n",
    "cv.imshow('blob', r)\n",
    "text = f'Blob shape={blob.shape}'\n",
    "cv.displayOverlay('blob', text)\n",
    "cv.waitKey(1)\n",
    "\n",
    "net.setInput(blob)\n",
    "t0 = time.time()\n",
    "outputs = net.forward(ln)\n",
    "t = time.time()\n",
    "#print('time=', t-t0)\n",
    "\n",
    "#print(len(outputs))\n",
    "#for out in outputs:\n",
    "    #print(out.shape)\n",
    "\n",
    "def trackbar2(x):\n",
    "    confidence = x/100\n",
    "    r = r0.copy()\n",
    "    for output in np.vstack(outputs):\n",
    "        if output[4] > confidence:\n",
    "            x, y, w, h = output[:4]\n",
    "            p0 = int((x-w/2)*416), int((y-h/2)*416)\n",
    "            p1 = int((x+w/2)*416), int((y+h/2)*416)\n",
    "            cv.rectangle(r, p0, p1, 1, 1)\n",
    "    cv.imshow('blob', r)\n",
    "    text = f'Bbox confidence={confidence}'\n",
    "    cv.displayOverlay('blob', text)\n",
    "\n",
    "r0 = blob[0, 0, :, :]\n",
    "r = r0.copy()\n",
    "cv.imshow('blob', r)\n",
    "cv.createTrackbar('confidence', 'blob', 50, 101, trackbar2)\n",
    "trackbar2(50)\n",
    "\n",
    "boxes = []\n",
    "confidences = []\n",
    "classIDs = []\n",
    "h, w = img.shape[:2]\n",
    "\n",
    "for output in outputs:\n",
    "    for detection in output:\n",
    "        scores = detection[5:]\n",
    "        classID = np.argmax(scores)\n",
    "        confidence = scores[classID]\n",
    "        if confidence > 0.5:\n",
    "            box = detection[:4] * np.array([w, h, w, h])\n",
    "            (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "            x = int(centerX - (width / 2))\n",
    "            y = int(centerY - (height / 2))\n",
    "            box = [x, y, int(width), int(height)]\n",
    "            boxes.append(box)\n",
    "            confidences.append(float(confidence))\n",
    "            classIDs.append(classID)\n",
    "\n",
    "indices = cv.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "count_objects = 0\n",
    "count_person = 0\n",
    "if len(indices) > 0:\n",
    "    for i in indices.flatten():\n",
    "        (x, y) = (boxes[i][0], boxes[i][1])\n",
    "        (w, h) = (boxes[i][2], boxes[i][3])\n",
    "        color = [int(c) for c in colors[classIDs[i]]]\n",
    "        cv.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "        text = \"{}: {:.4f}\".format(classes[classIDs[i]], confidences[i])\n",
    "        cv.putText(img, text, (x, y - 5), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "        if \"person\" not in text:\n",
    "            count_objects += 1\n",
    "        else:\n",
    "            count_person += 1\n",
    "\n",
    "cv.imshow('window', img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c1c1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of objects:  2\n",
      "Total number of people:  1\n",
      "Total number of face:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of objects: \",count_objects)\n",
    "print(\"Total number of people: \",count_person)\n",
    "print(\"Total number of face: \",count_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8339ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
